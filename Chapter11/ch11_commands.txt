Commands


$ hdfs dfsadmin -report
$ df –h
$ hdfs dfsadmin -report
$ hdfs getconf –confkey dfs.datanode.data.dir
3.	By default, the memory used by Hadoop daemons is defined by properties in $HADOOP_HOME/etc/hadoop/hadoop-env.sh and $YARN_HOME/etc/hadoop/yarn-env.sh in the hadoop-env.sh and yarn-env.sh files respectively. This is shown in the following screenshot:
$ hdfs getconf –confkey mapreduce.map.memory.mb
$ hdfs getconf –confkey mapreduce.reduce.memory.mb
$ hdfs getconf –confkey yarn.app.mapreduce.am.resource.mb
$ hdfs getconf –confkey yarn.app.mapreduce.am.resource.mb
$ hdfs getconf –confkey yarn.scheduler.maximum-allocation-mb
$ hadoop jar mapreduce/hadoop-mapreduce-examples-2.7.2.jar teragen 100000 /bench
$ hadoop jar mapreduce/hadoop-mapreduce-examples-2.7.2.jar terasort /bench /out
$ ethtool eth0
$ iftop
$ netstat -s